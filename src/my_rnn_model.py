import tensorflow as tf
from nematus.rnn_model import Encoder, RNNModel
from nematus.sampling_utils import SamplingUtils
from nematus import layers, model_inputs


class HighLevelEncoder:
    """ High level Encoder based on the Nematus Encoder, which models the information
    on Sentence, Paragraph level.
    The only difference is that this class doesn't have to build an embedding layer.
    """
    def __init__(self, config, batch_size, dropout_input, dropout_hidden):
        if config.theano_compat:
            bias_type = layers.LegacyBiasType.THEANO_A
        else:
            bias_type = layers.LegacyBiasType.NEMATUS_COMPAT_FALSE

        with tf.variable_scope("forward-stack"):
            self.forward_encoder = layers.GRUStack(
                input_size=2*config.state_size,
                state_size=config.state_size,
                batch_size=batch_size,
                use_layer_norm=config.rnn_layer_normalization,
                legacy_bias_type=bias_type,
                dropout_input=dropout_input,
                dropout_state=dropout_hidden,
                stack_depth=config.rnn_enc_depth,
                transition_depth=config.rnn_enc_transition_depth,
                alternating=True,
                residual_connections=True,
                first_residual_output=1)

        with tf.variable_scope("backward-stack"):
            self.backward_encoder = layers.GRUStack(
                input_size=config.embedding_size,
                state_size=config.state_size,
                batch_size=batch_size,
                use_layer_norm=config.rnn_layer_normalization,
                legacy_bias_type=bias_type,
                dropout_input=dropout_input,
                dropout_state=dropout_hidden,
                stack_depth=config.rnn_enc_depth,   # TODO change a CLF specific enc depth
                transition_depth=config.rnn_enc_transition_depth,
                alternating=True,
                reverse_alternation=True,
                residual_connections=True,
                first_residual_output=1)

    def get_context(self, x, x_mask):
        """ 
        args:
            x: shape - [factors, seqLen, batch_size], type - numpy.array
            x_mask: shape - [seqLen, batch_size], type - numpy.array
        returns:
            embs: shape - [seqLen, batch_size, embed_size]
            concat_states: shape - [time_step, batch_size, state_size * 2]
        """
        with tf.variable_scope("forward-stack"):
            fwd_states = self.forward_encoder.forward(x, x_mask)

        with tf.variable_scope("backward-stack"):
            bwd_states = self.backward_encoder.forward(x, x_mask)

        # Concatenate the left-to-right and the right-to-left states, in that
        # order. This is for compatibility with models that were trained with
        # the Theano version.
        stack_depth = len(self.forward_encoder.grus)
        if stack_depth % 2 == 0:
            concat_states = tf.concat([bwd_states, fwd_states], axis=2)
        else:
            concat_states = tf.concat([fwd_states, bwd_states], axis=2)
        return concat_states


class MyModelInputs(object):
    def __init__(self, config):
        # variable dimensions
        seq_len, batch_size = None, None

        self.x = tf.placeholder(
            name='x',
            shape=(config.factors, seq_len, batch_size),
            dtype=tf.int32)

        self.x_mask = tf.placeholder(
            name='x_mask',
            shape=(seq_len, batch_size),
            dtype=tf.float32)

        self.y = tf.placeholder(
            name='y',
            shape=(seq_len, batch_size),
            dtype=tf.int32)

        self.y_mask = tf.placeholder(
            name='y_mask',
            shape=(seq_len, batch_size),
            dtype=tf.float32)

        self.training = tf.placeholder_with_default(
            False,
            name='training',
            shape=())


class RNNModelClf(RNNModel):
    def __init__(self, config):
        self.inputs = model_inputs.ModelInputs(config)
        # Dropout functions for words.
        # These probabilistically zero-out all embedding values for individual
        # words.
        dropout_source = None
        if config.rnn_use_dropout and config.rnn_dropout_source > 0.0:
            def dropout_source(x):
                return tf.layers.dropout(
                    x, noise_shape=(tf.shape(x)[0], tf.shape(x)[1], 1),
                    rate=config.rnn_dropout_source,
                    training=self.inputs.training)

        # Dropout functions for use within FF, GRU, and attention layers.
        # We use Gal and Ghahramani (2016)-style dropout, so these functions
        # will be used to create 2D dropout masks that are reused at every
        # timestep.
        dropout_embedding, dropout_hidden = None, None
        if config.rnn_use_dropout and config.rnn_dropout_embedding > 0.0:
            def dropout_embedding(e):
                return tf.layers.dropout(e, noise_shape=tf.shape(e),
                                         rate=config.rnn_dropout_embedding,
                                         training=self.inputs.training)
        if config.rnn_use_dropout and config.rnn_dropout_hidden > 0.0:
            def dropout_hidden(h):
                return tf.layers.dropout(h, noise_shape=tf.shape(h),
                                         rate=config.rnn_dropout_hidden,
                                         training=self.inputs.training)

        batch_size = tf.shape(self.inputs.x)[-1]  # dynamic value

        # word-level encoder which is shared with NMT
        with tf.variable_scope("encoder"):
            self.encoder = Encoder(config, batch_size, dropout_source,
                                   dropout_embedding, dropout_hidden)
            ctx, embs = self.encoder.get_context(self.inputs.x, self.inputs.x_mask)
            # ctx - a simple concate of bi-direction GRU states
            # [time_steps, batch_size, 2 * state_size]

        with tf.variable_scope("attention"):
            # reduce the dim of word
            # word_attn [batch_size, state_size * 2]
            self.word_attn_layer = layers.AttentionStep(
                                        context=ctx,
                                        context_state_size=2*config.state_size,
                                        context_mask=self.inputs.x_mask,
                                        state_size=config.state_size,
                                        hidden_size=2*config.state_size,
                                        use_layer_norm=config.rnn_layer_normalization,
                                        dropout_context=dropout_hidden,
                                        dropout_state=dropout_hidden)
            
            word_attn_context, _ = self.word_attn_layer.forward(self.inputs.x, self.inputs.x_mask)
        
        # reshape
        tf.reshape(word_attn_context, [])
        # sent-level encoder
        with tf.variable_scope("sent-encoder"):
            self.sent_encoder = HighLevelEncoder(config, batch_size, dropout_hidden, dropout_hidden)
            # ctx [time_step, batch_size, state_size * 2]
            sent_ctx = self.sent_encoder.get_context(self.inputs.x, self.inputs.x_mask)

        with tf.variable_scope("sent-attention"):
            # sent_attn [batch_size, state_size * 2]
            self.sent_attn_layer = layers.AttentionStep(
                context=sent_ctx, 
                context_state_size=2*config.state_size,
                context_mask=self.inputs.x_mask,
                state_size=config.state_size,
                hidden_size=2*config.state_size,
                use_layer_norm=config.rnn_layer_normalization,
                dropout_context=dropout_hidden,
                dropout_state=dropout_hidden)
        
        with tf.variable_scope("clf"):
            self.class_layer = layers.FeedForwardLayer()
            self.logits = None

        with tf.variable_scope("loss"):
            self.loss_layer = layers.Masked_cross_entropy_loss(
                self.inputs.y, self.inputs.y_mask, config.label_smoothing,
                training=self.inputs.training)
            self._loss_per_sentence = self.loss_layer.forward(self.logits)
            self._loss = tf.reduce_mean(self._loss_per_sentence, keepdims=False)

        self.sampling_utils = SamplingUtils(config)

class MemNet(object):
    pass