#!/usr/bin/env python3
#!/usr/bin/env python3
'''
Build a neural machine translation model with soft attention
'''
import collections
from datetime import datetime
import json
import os
import locale
import logging
import subprocess
import sys
import tempfile
import time

# Start logging.
level = logging.INFO
logging.basicConfig(level=level, format='%(levelname)s: %(message)s')

import numpy
import tensorflow as tf
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from config import write_config_to_json_file, read_config_from_cmdline
from learning_schedule import ConstantSchedule
import model_loader
import inference
import util
from rnn_model import HANModel, ContextAwareNMT
from model_updater import ModelUpdater
from data_iterator import NMTTextIterator, CLFTextIterator


def load_data(config):
    logging.info('Reading data...')
    assert config.mode in ('clf', 'nmt')
    if config.mode == 'clf':
        text_iterator = CLFTextIterator(
                            source_dataset=config.source_dataset,
                            target_dataset=config.target_dataset,
                            source_dicts=config.source_dicts,
                            target_dict=config.target_dict,
                            batch_size=config.batch_size,
                            maxlen_sent=config.maxlen_sent,
                            maxlen_word=config.maxlen_word,
                            source_vocab_sizes=config.source_vocab_sizes,
                            skip_empty=True,
                            shuffle_each_epoch=config.shuffle_each_epoch,
                            sort_by_length=False,
                            use_factor=(config.factors > 1),
                            maxibatch_size=config.maxibatch_size,
                            token_batch_size=config.token_batch_size,
                            keep_data_in_memory=True)

        if config.valid_freq and config.valid_source_dataset and config.valid_target_dataset:
            valid_text_iterator = CLFTextIterator(
                                    source_dataset=config.valid_source_dataset,
                                    target_dataset=config.valid_target_dataset,
                                    source_dicts=config.source_dicts,
                                    target_dict=config.target_dict,
                                    batch_size=config.batch_size,
                                    maxlen_sent=config.maxlen_sent,
                                    maxlen_word=config.maxlen_word,
                                    source_vocab_sizes=config.source_vocab_sizes,
                                    skip_empty=True,
                                    shuffle_each_epoch=config.shuffle_each_epoch,
                                    sort_by_length=False,
                                    use_factor=(config.factors > 1),
                                    maxibatch_size=config.maxibatch_size,
                                    token_batch_size=config.token_batch_size,
                                    keep_data_in_memory=True)
    
        else:
            logging.info('no validation set loaded')
            valid_text_iterator = None

    elif config.mode == 'nmt':
        text_iterator = NMTTextIterator(
                            source_dataset=config.source_dataset,
                            target_dataset=config.target_dataset,
                            source_dicts=config.source_dicts,
                            target_dict=config.target_dict,
                            batch_size=config.batch_size,
                            maxlen_sent=config.maxlen_sent,
                            maxlen_word=config.maxlen_word,
                            source_vocab_sizes=config.source_vocab_sizes,
                            target_vocab_size=config.target_vocab_size,
                            skip_empty=True,
                            shuffle_each_epoch=config.shuffle_each_epoch,
                            sort_by_length=False,
                            use_factor=(config.factors > 1),
                            maxibatch_size=config.maxibatch_size,
                            token_batch_size=config.token_batch_size,
                            keep_data_in_memory=True)

        if config.valid_freq and config.valid_source_dataset and config.valid_target_dataset:
            valid_text_iterator = NMTTextIterator(
                                        source_dataset=config.source_dataset,
                                        target_dataset=config.target_dataset,
                                        source_dicts=config.source_dicts,
                                        target_dict=config.target_dict,
                                        batch_size=config.batch_size,
                                        maxlen_sent=config.maxlen_sent,
                                        maxlen_word=config.maxlen_word,
                                        source_vocab_sizes=config.source_vocab_sizes,
                                        target_vocab_size=config.target_vocab_size,
                                        skip_empty=True,
                                        shuffle_each_epoch=config.shuffle_each_epoch,
                                        sort_by_length=False,
                                        use_factor=(config.factors > 1),
                                        maxibatch_size=config.maxibatch_size,
                                        token_batch_size=config.token_batch_size,
                                        keep_data_in_memory=True)
        else:
            logging.info('no validation set loaded')
            valid_text_iterator = None

    logging.info('Done')
    return text_iterator, valid_text_iterator


def train(config, sess):
    assert (config.prior_model != None and (tf.train.checkpoint_exists(os.path.abspath(config.prior_model))) or (config.map_decay_c==0.0)), \
    "MAP training requires a prior model file: Use command-line option --prior_model"

    # Construct the graph, with one model replica per GPU
    num_gpus = len(util.get_available_gpus())
    num_replicas = max(1, num_gpus)

    logging.info('Building model...')
    replicas = []
    for i in range(num_replicas):
        device_type = "GPU" if num_gpus > 0 else "CPU"
        device_spec = tf.DeviceSpec(device_type=device_type, device_index=i)
        with tf.device(device_spec):
            with tf.variable_scope(tf.get_variable_scope(), reuse=(i>0)):
                model_builder = HANModel if config.mode == 'clf' else ContextAwareNMT
                model = model_builder(config)
                replicas.append(model)

    init = tf.zeros_initializer(dtype=tf.int32)
    global_step = tf.get_variable('time', [], initializer=init, trainable=False)

    if config.learning_schedule == "constant":
        schedule = ConstantSchedule(config.learning_rate)
    else:
        logging.error('Learning schedule type is not valid: {}'.format(
            config.learning_schedule))
        sys.exit(1)

    if config.optimizer == 'adam':
        optimizer = tf.train.AdamOptimizer(learning_rate=schedule.learning_rate,
                                           beta1=config.adam_beta1,
                                           beta2=config.adam_beta2,
                                           epsilon=config.adam_epsilon)
    else:
        logging.error('No valid optimizer defined: {}'.format(config.optimizer))
        sys.exit(1)

    if config.summary_freq:
        summary_dir = (config.summary_dir if config.summary_dir is not None
                       else os.path.abspath(os.path.dirname(config.saveto)))
        writer = tf.summary.FileWriter(summary_dir, sess.graph)
    else:
        writer = None

    updater = ModelUpdater(config, num_gpus, replicas, optimizer, global_step, writer)

    saver, progress = model_loader.init_or_restore_variables(config, sess, train=True)

    global_step.load(progress.uidx, sess)

    #save model options
    write_config_to_json_file(config, config.saveto)

    text_iterator, valid_text_iterator = load_data(config)
    # x = numpy.random.randint(low=0, high=128, size=(10, 100, 100, 1)).tolist()
    # y = numpy.random.randint(low=0, high=10, size=(10,)).tolist()
    # test_iterator = zip([x] * 5, [y] * 5)
    total_loss = 0.
    n_secs, n_sents, n_words = 0, 0, 0
    last_time = time.time()
    logging.info("Initial uidx={}".format(progress.uidx))
    
    data_prepare_func = util.prepare_clf_data if config.mode == 'clf' else util.prepare_nmt_data

    for progress.eidx in range(progress.eidx, config.max_epochs):
        logging.info('Starting epoch {0}'.format(progress.eidx))
        for sections, labels in text_iterator:
        # for sections, labels in test_iterator:
            if len(sections[0][0][0]) != config.factors:
                logging.error('Mismatch between number of factors in settings ({0}), and number in training corpus ({1})\n'.format(config.factors, len(sections[0][0][0])))
                sys.exit(1)
            x_in, x_mask_in, y_in, y_mask_in = data_prepare_func(sections, labels, config.factors, maxlen=None)
            if x_in is None:
                logging.info('Minibatch with zero sample under length {0}'.format(config.maxlen))
                continue
            write_summary_for_this_batch = config.summary_freq and ((progress.uidx % config.summary_freq == 0) or (config.finish_after and progress.uidx % config.finish_after == 0))
            (factors, sentLen, wordLen, batch_size) = x_in.shape

            loss = updater.update(sess, x_in, x_mask_in, y_in, y_mask_in,
                                  write_summary_for_this_batch)
            total_loss += loss
            n_sents += sentLen
            n_words += sentLen * wordLen
            n_secs += batch_size
            progress.uidx += 1

            if config.disp_freq and progress.uidx % config.disp_freq == 0:
                duration = time.time() - last_time
                disp_time = datetime.now().strftime('[%Y-%m-%d %H:%M:%S]')
                logging.info('{0} Epoch: {1} Update: {2} Loss/Doc: {3:.5f} Words/sec: {4:.5f} Sents/sec: {5:.5f}'.format(disp_time, progress.eidx, progress.uidx, total_loss/n_secs, n_words/duration, n_sents/duration))
                last_time = time.time()
                total_loss = 0.
                n_secs, n_sents, n_words = 0, 0, 0

            if config.valid_freq and progress.uidx % config.valid_freq == 0:
                valid_score = validate(sess, replicas[0], config, valid_text_iterator)
                
                valid_ce = valid_score.ce
                if (len(progress.history_errs) == 0 or
                    valid_ce < min(progress.history_errs)):
                    progress.history_errs.append(valid_ce)
                    progress.bad_counter = 0
                    save_non_checkpoint(sess, saver, config.saveto)
                    progress_path = '{0}.progress.json'.format(config.saveto)
                    progress.save_to_json(progress_path)
                else:
                    progress.history_errs.append(valid_ce)
                    progress.bad_counter += 1
                    if progress.bad_counter > config.patience:
                        logging.info('Early Stop!')
                        progress.estop = True
                        break

                if config.mode == 'clf':
                    valid_f1_score = valid_score.f1_score
                    # decide wether save as the best-model or not
                    need_to_save = ((len(progress.valid_script_scores) == 0 or 
                            valid_f1_score > max(progress.valid_script_scores)))
                    progress.valid_script_scores.append(valid_f1_score)

                elif config.mode == 'nmt' and config.valid_script is not None:
                    score = validate_with_script(sess, replicas[0], config)
                    need_to_save = (score is not None and
                        (len(progress.valid_script_scores) == 0 or
                         score > max(progress.valid_script_scores)))
                    if score is None:
                        score = 0.0  # ensure a valid value is written
                    progress.valid_script_scores.append(score)

                if need_to_save:
                    progress.bad_counter = 0
                    save_path = config.saveto + ".best-valid"
                    save_non_checkpoint(sess, saver, save_path)
                    write_config_to_json_file(config, save_path)

                    progress_path = '{}.progress.json'.format(save_path)
                    progress.save_to_json(progress_path)

            if config.save_freq and progress.uidx % config.save_freq == 0:
                saver.save(sess, save_path=config.saveto, global_step=progress.uidx)
                write_config_to_json_file(config, "%s-%s" % (config.saveto, progress.uidx))

                progress_path = '{0}-{1}.progress.json'.format(config.saveto, progress.uidx)
                progress.save_to_json(progress_path)

            if config.finish_after and progress.uidx % config.finish_after == 0:
                logging.info("Maximum number of updates reached")
                saver.save(sess, save_path=config.saveto, global_step=progress.uidx)
                write_config_to_json_file(config, "%s-%s" % (config.saveto, progress.uidx))

                progress.estop=True
                progress_path = '{0}-{1}.progress.json'.format(config.saveto, progress.uidx)
                progress.save_to_json(progress_path)
                break
        if progress.estop:
            break


def validate(session, model, config, text_iterator):
    valid_score = collections.namedtuple('valid_score', ['ce', 'f1_score'])
    if config.mode == 'clf':
        ce, f1_score = _validate_clf(session, model, config, text_iterator)
        return valid_score(ce, f1_score)
    else:
        ce = _validate_nmt(session, model, config, text_iterator)
        return valid_score(ce, None)


def _validate_clf(session, model, config, text_iterator):
    ce_vals, y_pred, y_true = [], [], []
    for xx, yy in text_iterator:
        if len(xx[0][0][0]) != config.factors:
            logging.error('Mismatch between number of factors in settings ' \
                          '({0}) and number present in data ({1})'.format(
                          config.factors, len(xx[0][0][0])))
            sys.exit(1)
        x, x_mask, y, y_mask = util.prepare_clf_data(xx, yy, config.factors, maxlen=None)

        # Run the minibatch through the model to get the sentence-level cross
        # entropy values.
        feeds = {model.inputs.x: x,
                 model.inputs.x_mask: x_mask,
                 model.inputs.y: y,
                 model.inputs.y_mask: y_mask,
                 model.inputs.training: False}
        batch_ce_vals, batch_preds = session.run([model.loss_per_sec, model.preds], feed_dict=feeds)
        y_true.extend(y.ravel().tolist())
        y_pred.extend(batch_preds.tolist())
        ce_vals.extend(batch_ce_vals.tolist())
        logging.info("Seen {}".format(len(ce_vals)))
    
    mirco_precision = precision_score(y_true, y_pred, average='micro')
    mirco_recall = recall_score(y_true, y_pred, average='micro')
    mirco_f1_score = f1_score(y_true, y_pred, average='micro')
    acc_score = accuracy_score(y_true, y_pred)

    num_secs = len(ce_vals)
    sum_ce = sum(ce_vals)
    avg_ce = sum_ce / num_secs

    logging.info('Validation external score (Accuracy/Precision/Recall/F1-Score) : {0:.5f} ' \
                 '{1:.5f} {2:.5f} {3:.5f}'.format(acc_score, mirco_precision, mirco_recall, mirco_f1_score))
    logging.info('Validation cross entropy (AVG/SUM): {0:.5f} {1:.5f}'.format(avg_ce, sum_ce))

    return avg_ce, mirco_f1_score


def _validate_nmt(session, model, config, text_iterator):
    ce_vals, token_counts = [], []
    for xx, yy in text_iterator:
        if len(xx[0][0][0]) != config.factors:
            logging.error('Mismatch between number of factors in settings ' \
                          '({0}) and number present in data ({1})'.format(
                          config.factors, len(xx[0][0][0])))
            sys.exit(1)
        x, x_mask, y, y_mask = util.prepare_nmt_data(xx, yy, config.factors,
                                                 maxlen=None)
        # Run the minibatch through the model to get the sentence-level cross
        # entropy values.
        feeds = {model.inputs.x: x,
                 model.inputs.x_mask: x_mask,
                 model.inputs.y: y,
                 model.inputs.y_mask: y_mask,
                 model.inputs.training: False}
        batch_ce_vals = session.run(model.loss_per_sentence, feed_dict=feeds)

        word_len = y_mask.shape[1]
        batch_token_counts = [numpy.count_nonzero(s) for s in 
                                            numpy.reshape(
                                                numpy.transpose(y_mask, (0, 2, 1)),
                                                (-1, word_len))]
        print(len(batch_token_counts))
        print(batch_ce_vals.shape[0])
        ce_vals += list(batch_ce_vals)
        token_counts += batch_token_counts
        logging.info("Seen {}".format(len(ce_vals)))

    assert len(ce_vals) == len(token_counts)
    num_sents = len(ce_vals)
    num_tokens = sum(token_counts)
    sum_ce = sum(ce_vals)
    avg_ce = sum_ce / num_sents
    logging.info('Validation cross entropy (AVG/SUM/N_SENTS/N_TOKENS): {0:.5f} ' \
                 '{1:.5f} {2:.5f} {3:.5f}'.format(avg_ce, sum_ce, num_sents, num_tokens))
    return avg_ce


def save_non_checkpoint(session, saver, save_path):
    """Saves the model to a temporary directory then moves it to save_path.

    Rationale: we use TensorFlow's standard tf.train.Saver mechanism for saving
    training checkpoints and also for saving the current best model according
    to validation metrics. Since these are all stored in the same directory,
    their paths would normally all get written to the same 'checkpoint' file,
    with the file containing whichever one was last saved. That creates a
    problem if training is interrupted after a best-so-far model is saved but
    before a regular checkpoint is saved, since Nematus will try to load the
    best-so-far model instead of the last checkpoint when it is restarted. To
    avoid this, we save the best-so-far models to a temporary directory, then
    move them to their desired location. The 'checkpoint' file that is written
    to the temporary directory can safely be deleted along with the directory.

    Args:
        session: a TensorFlow session.
        saver: a tf.train.Saver
        save_path: string containing the path to save the model to.

    Returns:
        None.
    """
    head, tail = os.path.split(save_path)
    assert tail != ""
    base_dir = "." if head == "" else head
    with tempfile.TemporaryDirectory(dir=base_dir) as tmp_dir:
        tmp_save_path = os.path.join(tmp_dir, tail)
        saver.save(session, save_path=tmp_save_path)
        for filename in os.listdir(tmp_dir):
            if filename == 'checkpoint':
                continue
            new = os.path.join(tmp_dir, filename)
            old = os.path.join(base_dir, filename)
            os.replace(src=new, dst=old)


def validate_with_script(session, model, config):
    if config.valid_script == None:
        return None
    logging.info('Starting external validation.')
    out = tempfile.NamedTemporaryFile(mode='w')
    inference.translate_file(input_file=open(config.valid_source_dataset),
                             output_file=out,
                             session=session,
                             models=[model],
                             configs=[config],
                             beam_size=config.beam_size,
                             normalization_alpha=config.normalization_alpha)
    out.flush()
    args = [config.valid_script, out.name]
    proc = subprocess.Popen(args, stdin=None, stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    stdout_bytes, stderr_bytes = proc.communicate()
    encoding = locale.getpreferredencoding()
    stdout = stdout_bytes.decode(encoding=encoding)
    stderr = stderr_bytes.decode(encoding=encoding)
    if len(stderr) > 0:
        logging.info("Validation script wrote the following to standard "
                     "error:\n" + stderr)
    if proc.returncode != 0:
        logging.warning("Validation script failed (returned exit status of "
                        "{}).".format(proc.returncode))
        return None
    try:
        score = float(stdout.split()[0])
    except:
        logging.warning("Validation script output does not look like a score: "
                        "{}".format(stdout))
        return None
    logging.info("Validation script score: {}".format(score))
    return score

if __name__ == "__main__":
    # Parse command-line arguments.
    config = read_config_from_cmdline()
    logging.info(config)

    # Create the TensorFlow session.
    tf_config = tf.ConfigProto()
    tf_config.allow_soft_placement = True

    # Train.
    with tf.Session(config=tf_config) as sess:
        train(config, sess)
