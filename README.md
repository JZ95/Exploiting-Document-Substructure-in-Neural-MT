# Exploiting Predictable Document Sub-structure in NMT

## Intro

## Model Architecutre
![](./imgs/model-arch.pdf)

## Training strategy
1. Train baseline NMT (sent-independent)
2. Train text clf (reusing the word embedding and word-level encoder in the baseline-NMT)
3. Finetuning the context-aware NMT

## Usage

## Nematus
This project is based on nematus v0.4, specifically the [commit 75a168d247e50a746a717be0ac514e7c314246d3](https://github.com/EdinburghNLP/nematus/tree/75a168d247e50a746a717be0ac514e7c314246d3). The support for Transformer Model, Server Translator, MAP training, rescore is removed for simplicity.